{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afbb588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pypose as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ff76e3",
   "metadata": {},
   "source": [
    "# 1. Intialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77de72ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: so3Type Group:\n",
      "tensor([[-0.4009,  1.0486, -0.0641],\n",
      "        [ 0.6245, -0.5652,  0.9019]]) \n",
      "x.shape: torch.Size([2, 1, 7]) \n",
      "x.gshape: torch.Size([2, 1])\n",
      "SE3Type Group:\n",
      "tensor([[0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1.]])\n",
      "se3Type Group:\n",
      "tensor([[[-0.5171, -1.1020, -0.6251, -0.5961,  2.9070,  0.2051],\n",
      "         [-0.4160, -0.8013,  0.3193, -0.7172,  1.4841, -0.1545]],\n",
      "\n",
      "        [[ 0.9216,  1.2305, -1.0666,  1.1960, -1.3424, -0.4081],\n",
      "         [ 0.6565,  0.4741, -0.8166, -1.2900,  0.5438, -1.8964]]])\n"
     ]
    }
   ],
   "source": [
    "a = pp.so3(torch.randn(2,3))\n",
    "x = pp.identity_SE3(2,1)\n",
    "y = pp.randn_se3(2,2)\n",
    "print('a:', a, '\\nx.shape:', x.shape, '\\nx.gshape:', x.gshape)\n",
    "print(x.gview(2))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cff3249",
   "metadata": {},
   "source": [
    "### All arguments in PyTorch are supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3003efc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SO3Type Group:\n",
       " tensor([[-0.1872, -0.0170, -0.1539,  0.9700],\n",
       "         [ 0.0393, -0.5652, -0.1045,  0.8174],\n",
       "         [ 0.3654,  0.1013,  0.5684,  0.7301]], device='cuda:0',\n",
       "        dtype=torch.float64, requires_grad=True),\n",
       " SO3Type Group:\n",
       " tensor([[-0.1872, -0.0170, -0.1539,  0.9700],\n",
       "         [ 0.0393, -0.5652, -0.1045,  0.8174],\n",
       "         [ 0.3654,  0.1013,  0.5684,  0.7301]], device='cuda:0',\n",
       "        grad_fn=<AliasBackward0>))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pp.randn_SO3(3, device=\"cuda:0\", dtype=torch.double, requires_grad=True)\n",
    "b = pp.identity_like(a, device=\"cpu\")\n",
    "a, b\n",
    "t = a.float()\n",
    "a, t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-archives",
   "metadata": {},
   "source": [
    "# 2. Slicing and Shaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "welsh-assembly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: torch.Size([2, 2])\n",
      "B: torch.Size([2, 1])\n",
      "C: torch.Size([2, 3])\n",
      "D: torch.Size([3])\n",
      "E: torch.Size([2, 1])\n",
      "F: torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "A = pp.randn_SO3(2,2)\n",
    "B = pp.randn_SO3(2,1)\n",
    "C = torch.cat([A,B], dim=1)         # Tensor cat\n",
    "C[0,1] = pp.randn_SO3(1)            # Slicing set\n",
    "D = C[1,:].Log()                    # Slicing get\n",
    "E, F = torch.split(C, [1,2], dim=1) # Tensor split\n",
    "print('A:', A.gshape)\n",
    "print('B:', B.gshape)\n",
    "print('C:', C.gshape)\n",
    "print('D:', D.gshape)\n",
    "print('E:', E.gshape)\n",
    "print('F:', F.gshape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ea61f8",
   "metadata": {},
   "source": [
    "# 3. Basic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6927dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "se3Type Group:\n",
       "tensor([[[ 0.5171,  1.1020,  0.6251,  0.5961, -2.9070, -0.2051],\n",
       "         [ 0.4160,  0.8013, -0.3193,  0.7172, -1.4841,  0.1545]],\n",
       "\n",
       "        [[-0.9216, -1.2305,  1.0666, -1.1960,  1.3424,  0.4081],\n",
       "         [-0.6565, -0.4741,  0.8166,  1.2900, -0.5438,  1.8964]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x * y.Exp()).Inv().Log()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94d83b4",
   "metadata": {},
   "source": [
    "# 4. Adjoint Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23028575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "X = pp.randn_Sim3(6, dtype=torch.double)\n",
    "a = pp.randn_sim3(6, dtype=torch.double)\n",
    "b = X.AdjT(a)\n",
    "print((X * b.Exp() - a.Exp() * X).abs().mean() < 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8a2cca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "X = pp.randn_SE3(8)\n",
    "a = pp.randn_se3(8)\n",
    "b = X.Adj(a)\n",
    "print((b.Exp() * X - X * a.Exp()).abs().mean() < 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef005df",
   "metadata": {},
   "source": [
    "# 5. Grdients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "331ff3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0827, device='cuda:0', grad_fn=<AliasBackward0>),\n",
       " tensor([[ 0.1487, -0.2074,  0.2507],\n",
       "         [ 0.0400,  0.2287, -0.1283],\n",
       "         [ 0.2544,  0.2409,  0.0989]], device='cuda:0'),\n",
       " so3Type Group:\n",
       " tensor([[ 0.0743, -0.1037,  0.1254],\n",
       "         [ 0.0200,  0.1143, -0.0641],\n",
       "         [ 0.1272,  0.1205,  0.0494]], device='cuda:0', requires_grad=True),\n",
       " so3Type Group:\n",
       " tensor([[ 0.0743, -0.1037,  0.1254],\n",
       "         [ 0.0200,  0.1143, -0.0641],\n",
       "         [ 0.1272,  0.1205,  0.0494]], device='cuda:0'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pp.randn_so3(3, sigma=0.1, requires_grad=True, device=\"cuda\")\n",
    "assert x.is_leaf\n",
    "loss = (x.Exp().Log()**2).sin().sum() # Just test, No physical meaning\n",
    "loss.backward()\n",
    "y = x.detach()\n",
    "loss, x.grad, x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7c91bb",
   "metadata": {},
   "source": [
    "# 6. Test a Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bd984bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Optimization:\n",
      " so3Type Group:\n",
      "Parameter containing:\n",
      "tensor([[ 0.6965,  0.9209,  0.8660],\n",
      "        [ 1.6618,  0.1517, -1.1111],\n",
      "        [ 0.2451,  0.7669,  1.2152],\n",
      "        [-0.7460,  0.1278,  0.5047]], device='cuda:0', requires_grad=True)\n",
      "tensor(7.2796, device='cuda:0', grad_fn=<AliasBackward0>)\n",
      "tensor(6.9272, device='cuda:0', grad_fn=<AliasBackward0>)\n",
      "tensor(6.6190, device='cuda:0', grad_fn=<AliasBackward0>)\n",
      "tensor(6.1722, device='cuda:0', grad_fn=<AliasBackward0>)\n",
      "tensor(7.0664, device='cuda:0', grad_fn=<AliasBackward0>)\n",
      "Parameter: 12\n",
      "After Optimization:\n",
      " so3Type Group:\n",
      "Parameter containing:\n",
      "tensor([[-0.5233,  0.1666, -0.1501],\n",
      "        [ 0.7642, -0.4101,  0.4685],\n",
      "        [-0.0640, -0.0837, -0.2574],\n",
      "        [-0.3928, -0.7736, -0.3618]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "class TestNet(nn.Module):\n",
    "    def __init__(self, n):\n",
    "        super().__init__()\n",
    "        self.weight = pp.Parameter(pp.randn_so3(n))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.weight.Exp() * x\n",
    "\n",
    "\n",
    "n,epoch = 4, 5\n",
    "net = TestNet(n).cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = 0.2, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[2,4], gamma=0.5)\n",
    "\n",
    "print(\"Before Optimization:\\n\", net.weight)\n",
    "for i in range(epoch):\n",
    "    optimizer.zero_grad()\n",
    "    inputs = pp.randn_SO3(n).cuda()\n",
    "    outputs = net(inputs)\n",
    "    loss = outputs.abs().sum()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    print(loss)\n",
    "\n",
    "print(\"Parameter:\", count_parameters(net))\n",
    "print(\"After Optimization:\\n\", net.weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
